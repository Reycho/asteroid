# ==============================================================================
# Enhanced NEA Resource Value Predictor with Multi-Target Learning
# ==============================================================================
import os
import sys
import numpy as np
import pandas as pd
import zipfile
import tensorflow as tf
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder, StandardScaler
from imblearn.over_sampling import SMOTE
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score
from tensorflow.keras.models import Model
from tensorflow.keras.layers import (Dense, Dropout, BatchNormalization,
                                     Input, Concatenate, GaussianNoise,
                                     Activation, Conv1D, MaxPooling1D,
                                     GlobalMaxPooling1D)
from tensorflow.keras.utils import to_categorical
from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.regularizers import l2
from sklearn.metrics import classification_report, confusion_matrix
import matplotlib.pyplot as plt
import seaborn as sns
import warnings
warnings.filterwarnings('ignore')

# ==============================================================================
# Configuration
# ==============================================================================
# Update these paths according to your setup
base_path = '.'  # or your local path
catalog_path = os.path.join(base_path, 'MITHNEOSCLEAN.csv')
spectra_zip_path = os.path.join(base_path, 'visnir_files.zip')
model_save_path = os.path.join(base_path, 'resource_value_model.keras')

# Resource value mapping based on asteroid taxonomy and composition
RESOURCE_VALUE_MAP = {
    'C': 0.3,   # C-type: low metal, water potential
    'S': 0.7,   # S-type: moderate metals, silicates
    'X': 0.9,   # X-type: high metal content
    'M': 0.95,  # M-type: metallic, highest value
    'V': 0.6,   # V-type: basaltic, moderate value
    'A': 0.4,   # A-type: olivine-rich, low-moderate value
    'D': 0.2,   # D-type: organic-rich, low metal value
    'T': 0.25,  # T-type: similar to D-type
    'B': 0.35,  # B-type: similar to C-type but slightly higher
    'F': 0.3,   # F-type: similar to C-type
    'G': 0.35,  # G-type: similar to C-type
    'P': 0.2,   # P-type: very low albedo, organic materials
    'R': 0.5,   # R-type: olivine-pyroxene rich
    'E': 0.8,   # E-type: enstatite, potential metals
    'Q': 0.65,  # Q-type: ordinary chondrite-like
    'L': 0.4,   # L-type: unusual spectrum
    'K': 0.45,  # K-type: intermediate
    'Sq': 0.68, # S-subtype
    'Sr': 0.72, # S-subtype
    'Sw': 0.66, # S-subtype
    'Sa': 0.7,  # S-subtype
    'Sk': 0.69, # S-subtype
    'Sl': 0.71, # S-subtype
    'Xc': 0.85, # X-subtype
    'Xe': 0.92, # X-subtype
    'Xk': 0.88, # X-subtype
}

# ==============================================================================
# Enhanced Filename Mapping Function
# ==============================================================================
def create_filename_map(spectra_zip_path):
    """Creates a robust filename mapping with multiple format support."""
    file_map = {}
    print(f"Scanning zip archive: {spectra_zip_path} to build filename map...")

    if not os.path.exists(spectra_zip_path):
        print(f"ERROR: Zip archive {spectra_zip_path} does not exist!")
        return file_map

    with zipfile.ZipFile(spectra_zip_path, 'r') as zip_ref:
        for filename in zip_ref.namelist():
            if (filename.endswith('.txt') or filename.endswith('.dat')) and not filename.startswith('__MACOSX'):
                try:
                    # Extract the base name of the file
                    base_filename = os.path.basename(filename)
                    # Handle various filename formats
                    if base_filename.startswith('a') and len(base_filename) > 7:
                        # Format: a000001.txt
                        asteroid_id = int(base_filename[1:7])
                        file_map[asteroid_id] = filename
                    elif base_filename.startswith('a'):
                        # Format: a1.txt, a289.txt
                        parts = base_filename.replace('a', '').replace('.txt', '').replace('.dat', '')
                        asteroid_id = int(parts)
                        file_map[asteroid_id] = filename
                    else:
                        # Format: 1.txt, 289.txt
                        parts = base_filename.replace('.txt', '').replace('.dat', '').split('.')[0]
                        asteroid_id = int(parts)
                        file_map[asteroid_id] = filename

                except (ValueError, IndexError):
                    print(f"Warning: Could not parse asteroid ID from filename: {filename}")
                    continue

    print(f"Successfully created map with {len(file_map)} entries.")
    return file_map

# ==============================================================================
# Advanced Spectral Feature Extraction
# ==============================================================================
def extract_spectral_features(wavelength, reflectance):
    """Extract comprehensive spectral features for resource assessment."""
    features = {}
    
    # Basic spectral parameters
    features['mean_reflectance'] = np.mean(reflectance)
    features['std_reflectance'] = np.std(reflectance)
    features['min_reflectance'] = np.min(reflectance)
    features['max_reflectance'] = np.max(reflectance)
    features['reflectance_range'] = np.ptp(reflectance)
    
    # Spectral slope (indicator of composition)
    if len(wavelength) > 1:
        slope = np.polyfit(wavelength, reflectance, 1)[0]
        features['spectral_slope'] = slope
        
        # Visible slope (0.5-0.9 μm) - important for S-type identification
        vis_mask = (wavelength >= 0.5) & (wavelength <= 0.9)
        if np.sum(vis_mask) > 5:
            vis_slope = np.polyfit(wavelength[vis_mask], reflectance[vis_mask], 1)[0]
            features['visible_slope'] = vis_slope
        else:
            features['visible_slope'] = slope
    
    # Band analysis for mineral identification
    absorption_bands = []
    
    # 1 μm band (olivine/pyroxene - indicates S-type asteroids)
    if np.min(wavelength) <= 1.0 <= np.max(wavelength):
        idx_1um = np.argmin(np.abs(wavelength - 1.0))
        if 2 < idx_1um < len(reflectance) - 2:
            continuum = np.mean([reflectance[idx_1um-2], reflectance[idx_1um+2]])
            if continuum > 0:
                band_depth = 1 - (reflectance[idx_1um] / continuum)
                features['band_1um_depth'] = max(0, band_depth)
                absorption_bands.append(band_depth)
    
    # 2 μm band (pyroxene - strong in S-types)
    if np.min(wavelength) <= 2.0 <= np.max(wavelength):
        idx_2um = np.argmin(np.abs(wavelength - 2.0))
        if 2 < idx_2um < len(reflectance) - 2:
            continuum = np.mean([reflectance[idx_2um-2], reflectance[idx_2um+2]])
            if continuum > 0:
                band_depth = 1 - (reflectance[idx_2um] / continuum)
                features['band_2um_depth'] = max(0, band_depth)
                absorption_bands.append(band_depth)
    
    # 0.7 μm feature (space weathering indicator)
    if np.min(wavelength) <= 0.7 <= np.max(wavelength):
        idx_07um = np.argmin(np.abs(wavelength - 0.7))
        if 1 < idx_07um < len(reflectance) - 1:
            continuum = (reflectance[idx_07um-1] + reflectance[idx_07um+1]) / 2
            if continuum > 0:
                band_depth = 1 - (reflectance[idx_07um] / continuum)
                features['band_07um_depth'] = max(0, band_depth)
    
    # Color indices for composition discrimination
    try:
        # Near-IR to visible ratio (metal indicator)
        if np.min(wavelength) <= 0.55 <= np.max(wavelength) and np.min(wavelength) <= 1.6 <= np.max(wavelength):
            idx_055 = np.argmin(np.abs(wavelength - 0.55))
            idx_160 = np.argmin(np.abs(wavelength - 1.6))
            if reflectance[idx_055] > 0:
                features['nir_vis_ratio'] = reflectance[idx_160] / reflectance[idx_055]
        
        # Blue-red color index
        if np.min(wavelength) <= 0.45 <= np.max(wavelength) and np.min(wavelength) <= 0.75 <= np.max(wavelength):
            idx_045 = np.argmin(np.abs(wavelength - 0.45))
            idx_075 = np.argmin(np.abs(wavelength - 0.75))
            if reflectance[idx_045] > 0:
                features['blue_red_ratio'] = reflectance[idx_075] / reflectance[idx_045]
    except:
        features['nir_vis_ratio'] = 1.0
        features['blue_red_ratio'] = 1.0
    
    # Curvature analysis
    if len(reflectance) > 2:
        second_derivative = np.diff(reflectance, n=2)
        features['spectral_curvature'] = np.mean(second_derivative)
        features['curvature_std'] = np.std(second_derivative)
    
    # Band strength (sum of absorption features)
    features['total_band_strength'] = sum(absorption_bands) if absorption_bands else 0.0
    
    # Fill missing features with defaults
    default_features = [
        'band_1um_depth', 'band_2um_depth', 'band_07um_depth',
        'visible_slope', 'spectral_curvature', 'curvature_std'
    ]
    for feature in default_features:
        if feature not in features:
            features[feature] = 0.0

    if 'nir_vis_ratio' not in features:
        features['nir_vis_ratio'] = 1.0
    if 'blue_red_ratio' not in features:
        features['blue_red_ratio'] = 1.0
    
    return features

# ==============================================================================
# Resource Value Assignment
# ==============================================================================
def assign_resource_value(taxonomy):
    """Assign resource value based on asteroid taxonomy."""
    # Clean taxonomy string
    taxonomy_clean = str(taxonomy).strip().upper()
    
    # Direct match
    if taxonomy_clean in RESOURCE_VALUE_MAP:
        return RESOURCE_VALUE_MAP[taxonomy_clean]
    
    # Fuzzy matching for complex taxonomies
    for key in RESOURCE_VALUE_MAP:
        if key in taxonomy_clean:
            return RESOURCE_VALUE_MAP[key]
    
    # Default for unknown types (conservative estimate)
    return 0.3

# ==============================================================================
# Enhanced Data Preparation
# ==============================================================================
def prepare_data_for_classification(zip_file, catalog, file_map):
    """Prepare data for asteroid classification."""
    common_wavelength = np.linspace(0.45, 2.45, 200)

    resampled_spectra = []
    spectral_features = []
    taxonomies = []
    asteroid_ids = []

    print("Processing spectra for classification...")
    
    catalog.dropna(subset=['Number', 'Simplified Category'], inplace=True)

    for _, row in catalog.iterrows():
        asteroid_id = int(row['Number'])
        if asteroid_id in file_map:
            filename = file_map[asteroid_id]
            try:
                with zip_file.open(filename) as f:
                    spectrum = np.loadtxt(f, comments='#', usecols=(0, 1))
                if spectrum.shape[0] < 10: continue

                wavelength, reflectance = spectrum[:, 0], spectrum[:, 1]
                mask = np.isfinite(wavelength) & np.isfinite(reflectance) & (reflectance > 0)
                wavelength, reflectance = wavelength[mask], reflectance[mask]
                if len(wavelength) < 10: continue

                if np.median(reflectance) > 0:
                    reflectance /= np.median(reflectance)
                
                q1, q3 = np.percentile(reflectance, [5, 95])
                reflectance = np.clip(reflectance, q1, q3)

                features = extract_spectral_features(wavelength, reflectance)
                resampled_reflectance = np.interp(common_wavelength, wavelength, reflectance)
                
                try:
                    from scipy.ndimage import gaussian_filter1d
                    resampled_reflectance = gaussian_filter1d(resampled_reflectance, sigma=0.5)
                except ImportError:
                    kernel = np.ones(3) / 3
                    resampled_reflectance = np.convolve(resampled_reflectance, kernel, mode='same')

                resampled_spectra.append(resampled_reflectance)
                spectral_features.append(list(features.values()))
                taxonomies.append(row['Simplified Category'])
                asteroid_ids.append(asteroid_id)
            except Exception as e:
                print(f"Warning: Error processing {filename}: {str(e)}")
                continue
    
    print(f"Successfully processed {len(resampled_spectra)} spectra.")
    if not resampled_spectra:
        return None, None, None, None

    X_spectra = np.array(resampled_spectra).reshape(-1, len(common_wavelength), 1)
    X_features = np.array(spectral_features)
    
    return X_spectra, X_features, taxonomies, asteroid_ids

# ==============================================================================
# Classification Model Architecture
# ==============================================================================
def create_classifier_model(spectral_shape, feature_shape, num_classes):
    """Creates a model for asteroid classification."""
    spectral_input = Input(shape=spectral_shape, name='spectral_input')
    x = Conv1D(32, 15, padding='same', activation='relu')(spectral_input)
    x = BatchNormalization()(x)
    x = MaxPooling1D(2)(x)
    x = Dropout(0.2)(x)
    x = Conv1D(64, 10, padding='same', activation='relu')(x)
    x = BatchNormalization()(x)
    x = MaxPooling1D(2)(x)
    x = Dropout(0.3)(x)
    x = Conv1D(128, 5, padding='same', activation='relu')(x)
    x = BatchNormalization()(x)
    x = GlobalMaxPooling1D()(x)
    x = Dropout(0.4)(x)

    feature_input = Input(shape=(feature_shape,), name='feature_input')
    f = Dense(64, activation='relu', kernel_regularizer=l2(0.001))(feature_input)
    f = BatchNormalization()(f)
    f = Dropout(0.3)(f)
    f = Dense(32, activation='relu', kernel_regularizer=l2(0.001))(f)
    f = BatchNormalization()(f)
    f = Dropout(0.2)(f)

    combined = Concatenate()([x, f])
    z = Dense(256, activation='relu', kernel_regularizer=l2(0.001))(combined)
    z = BatchNormalization()(z)
    z = Dropout(0.5)(z)
    z = Dense(128, activation='relu')(z)
    z = Dropout(0.4)(z)
    
    class_output = Dense(num_classes, activation='softmax', name='class_output')(z)
    
    model = Model(inputs=[spectral_input, feature_input], outputs=class_output)
    return model

# ==============================================================================
# Training and Evaluation
# ==============================================================================
def train_classifier_model(X_spectra, X_features, y_cat, class_labels):
    """Train and evaluate the asteroid classification model."""
    print("\n" + "="*60)
    print("TRAINING ASTEROID CLASSIFICATION MODEL")
    print("="*60)
    
    num_classes = len(class_labels)

    X_spec_train, X_spec_test, X_feat_train, X_feat_test, y_train, y_test = train_test_split(
        X_spectra, X_features, y_cat, test_size=0.2, random_state=42, stratify=np.argmax(y_cat, axis=1))
    
    X_spec_train, X_spec_val, X_feat_train, X_feat_val, y_train, y_val = train_test_split(
        X_spec_train, X_feat_train, y_train, test_size=0.25, random_state=42, stratify=np.argmax(y_train, axis=1))
    
    feature_scaler = StandardScaler()
    X_feat_train = feature_scaler.fit_transform(X_feat_train)
    X_feat_val = feature_scaler.transform(X_feat_val)
    X_feat_test = feature_scaler.transform(X_feat_test)

    # Reshape for SMOTE
    X_spec_train_reshaped = X_spec_train.reshape(X_spec_train.shape[0], -1)
    X_train_combined = np.concatenate((X_spec_train_reshaped, X_feat_train), axis=1)

    print(f"Original training samples: {len(y_train)}")
    smote = SMOTE(random_state=42, k_neighbors=2)
    X_train_res, y_train_res = smote.fit_resample(X_train_combined, y_train)
    print(f"Resampled training samples: {len(y_train_res)}")

    # Split back into spectral and feature data
    X_spec_train_res = X_train_res[:, :X_spec_train_reshaped.shape[1]].reshape(-1, X_spec_train.shape[1], 1)
    X_feat_train_res = X_train_res[:, X_spec_train_reshaped.shape[1]:]
    
    model = create_classifier_model((X_spectra.shape[1], 1), X_features.shape[1], num_classes)
    model.compile(optimizer=Adam(learning_rate=0.0005), loss='categorical_crossentropy', metrics=['accuracy'])
    
    model.summary()
    
    callbacks = [
        EarlyStopping(monitor='val_loss', patience=30, restore_best_weights=True, verbose=1),
        ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=15, min_lr=1e-6, verbose=1),
        ModelCheckpoint(model_save_path, monitor='val_loss', save_best_only=True, verbose=1)
    ]
    
    history = model.fit(
        [X_spec_train_res, X_feat_train_res], y_train_res,
        validation_data=([X_spec_val, X_feat_val], y_val),
        epochs=200, batch_size=32, callbacks=callbacks, verbose=2)

    print("\nEvaluating model...")
    y_pred_probs = model.predict([X_spec_test, X_feat_test])
    y_pred = np.argmax(y_pred_probs, axis=1)
    y_true = np.argmax(y_test, axis=1)

    print("\nClassification Report:")
    print(classification_report(y_true, y_pred, target_names=class_labels))

    print("\nConfusion Matrix:")
    cm = confusion_matrix(y_true, y_pred)
    plt.figure(figsize=(10, 8))
    sns.heatmap(cm, annot=True, fmt='d', xticklabels=class_labels, yticklabels=class_labels)
    plt.title('Confusion Matrix')
    plt.ylabel('Actual')
    plt.xlabel('Predicted')
    plt.show()

    return model, feature_scaler, history

# ==============================================================================
# Prediction Function
# ==============================================================================
def predict_asteroid_classes(model, feature_scaler, X_spectra, X_features, asteroid_ids, taxonomies, label_encoder):
    """Generate class predictions for all asteroids."""
    X_features_scaled = feature_scaler.transform(X_features)
    predictions = model.predict([X_spectra, X_features_scaled])
    predicted_classes = label_encoder.inverse_transform(np.argmax(predictions, axis=1))

    results = pd.DataFrame({
        'Asteroid_ID': asteroid_ids,
        'Original_Taxonomy': taxonomies,
        'Predicted_Taxonomy': predicted_classes,
    })
    
    # Add predicted probabilities for each class
    for i, class_label in enumerate(label_encoder.classes_):
        results[f'Prob_{class_label}'] = predictions[:, i]

    return results

# ==============================================================================
# Main Execution Function
# ==============================================================================
def main():
    """Main execution function."""
    np.random.seed(42)
    tf.random.set_seed(42)
    print("ASTEROID CLASSIFICATION")
    print("="*50)

    catalog = pd.read_csv(catalog_path)
    print(f"Loaded catalog with {len(catalog)} entries.")
    
    filename_map = create_filename_map(spectra_zip_path)
    if not filename_map: return

    with zipfile.ZipFile(spectra_zip_path, 'r') as zip_file:
        X_spectra, X_features, taxonomies, asteroid_ids = prepare_data_for_classification(zip_file, catalog, filename_map)

    if X_spectra is None:
        print("Data preparation failed.")
        return

    le = LabelEncoder()
    y_encoded = le.fit_transform(taxonomies)
    y_cat = to_categorical(y_encoded)
    
    model, feature_scaler, history = train_classifier_model(X_spectra, X_features, y_cat, le.classes_)

    print("\nGenerating predictions for all asteroids...")
    results = predict_asteroid_classes(model, feature_scaler, X_spectra, X_features, asteroid_ids, taxonomies, le)
    
    results_path = os.path.join(base_path, 'nea_classification_predictions.csv')
    results.to_csv(results_path, index=False)
    print(f"\nAll predictions saved to: {results_path}")
    
    scaler_path = os.path.join(base_path, 'classification_feature_scaler.pkl')
    import pickle
    with open(scaler_path, 'wb') as f:
        pickle.dump(feature_scaler, f)
    print(f"Feature scaler saved to: {scaler_path}")
    
    print(f"\nModel saved to: {model_save_path}")
    print("\nClassification complete!")
    
    return results

# ==============================================================================
# Execute if run as main
# ==============================================================================
if __name__ == '__main__':
    results = main()
